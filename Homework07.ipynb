{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QshK8s21WBrf"
   },
   "source": [
    "# Homework07\n",
    "\n",
    "Exercises to practice pandas, data analysis and classification\n",
    "\n",
    "## Goals\n",
    "\n",
    "- Understand the effects of pre-processing data\n",
    "- Get familiar with the ML flow: encode -> normalize -> train -> evaluate\n",
    "- Understand the difference between regression and classification tasks\n",
    "- Build an intuition for different classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Hf8SXUwWOho"
   },
   "source": [
    "### Setup\n",
    "\n",
    "Run the following 2 cells to import all necessary libraries and helpers for this homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/PSAM-5020-2025S-A/5020-utils/raw/main/src/data_utils.py\n",
    "!wget -q https://github.com/PSAM-5020-2025S-A/5020-utils/raw/main/src/image_utils.py\n",
    "\n",
    "!wget -qO- https://github.com/PSAM-5020-2025S-A/5020-utils/releases/latest/download/0801-500.tar.gz | tar xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import PIL.Image as PImage\n",
    "\n",
    "from os import listdir, path\n",
    "\n",
    "from data_utils import RandomForestClassifier, SVC\n",
    "from data_utils import classification_error, display_confusion_matrix, regression_error\n",
    "\n",
    "from image_utils import get_pixels, make_image\n",
    "\n",
    "from Homework07_utils import CamUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "The dataset we are going to use has images from $25$ different security cameras, and our task is to separate them by camera. Some of the cameras move, some of them don't, and there are more than $1000$ images, so there's no way we want to do this by hand.\n",
    "\n",
    "### Loading Data\n",
    "\n",
    "If we look at the images in `./data/image/0801-500/train/`, we'll notice that they are named and organized in a very particular way. They're all in the same directory and the first part of their filename specifies which camera they came from. Even though those `ids` are numbers, they're not sequential, so we'll use some helper functions to extract a unique `label` from their filenames.\n",
    "\n",
    "This is exactly what the `OrdinalEncoder` class does, but since we only have to encode this one column, we'll do it by hand while we read the files in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this creates a list of all the files in a given directory, that end in .jpg\n",
    "train_files = [f for f in listdir(\"./data/image/0801-500/train\") if f.endswith(\".jpg\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: check and see what is inside the list here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll read the image pixels and extract their labels. `CamUtils.get_label()` is the helper function we'll use to \"encode\" and return a label id based on the filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_data = []\n",
    "label_data = []\n",
    "\n",
    "for fname in train_files:\n",
    "  label = CamUtils.get_label(fname)\n",
    "  img = PImage.open(path.join(\"./data/image/0801-500/train\", fname))\n",
    "  pixel_data.append(get_pixels(img))\n",
    "  label_data.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: check if labels got extracted correctly by looking at \n",
    "#       the first few items of the label list and the filename list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels and the filenames won't match exactly since labels start at $0$ and the filenames start at $01$ and skip some numbers.\n",
    "\n",
    "We can open some images from pixels, just to make sure we loaded them correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(make_image(pixel_data[0]))\n",
    "display(make_image(pixel_data[10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now might not be a bad time to peek into the `data/image/0801-500/` directories to see what's inside them and what the images look like.... and get to know the data..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame it\n",
    "\n",
    "Let's put our raw pixel data into a `DataFrame`, and create a column for storing each image's label.\n",
    "\n",
    "(this next cell might take a while to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(pixel_data)\n",
    "train_df[\"label\"] = label_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect our `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insight\n",
    "\n",
    "<span style=\"color:hotpink\">\n",
    "Does anything stand out as peculiar about the feature values in our <code>DataFrame</code>?<br>\n",
    "Do we have to encode or scale our data?<br>\n",
    "Why? Or, why not?<br>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">EDIT THIS CELL WITH ANSWER</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Files\n",
    "\n",
    "If that worked, repeat the process for the test files inside the `./data/image/0801-500/test/` directory.\n",
    "\n",
    "We can almost use the exact same steps as we did above to create a `DataFrame`, the only difference being that we don't have labels for these images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: create a list of files in the test/ directory\n",
    "test_files = []\n",
    "\n",
    "# TODO: check its length and content\n",
    "\n",
    "test_pixel_data = []\n",
    "\n",
    "# TODO: loop over files and load their pixels into a list\n",
    "\n",
    "# TODO: load into DataFrame (this might take 20 - 30 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like data!!\n",
    "\n",
    "We could train a `RandomForestClassifier` directly on this `DataFrame` and see what would happen, but my guess is that Python runs out of memory and crashes our tab/browser/computer...\n",
    "\n",
    "We'll use _projection_ to reduce the number of dimensions in our dataset. Projection is when we just drop some of the columns in our dataset. \n",
    "\n",
    "Which columns ? That's up to us.\n",
    "\n",
    "Let's first try using the first $N$ columns/features where $N$ is a number around $10$.\n",
    "\n",
    "This is how we get the first $N$ columns from a `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split input and output features\n",
    "NUM_FEATURES = 10\n",
    "chosen_columns = train_df.columns[:NUM_FEATURES]\n",
    "train_features = train_df[chosen_columns]\n",
    "\n",
    "out_features = train_df[\"label\"]\n",
    "\n",
    "# also separate test dataset features\n",
    "test_features = test_df[chosen_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our [Week 07](https://github.com/PSAM-5020-2025S-A/WK07) notebook, we can create a classification model by following these steps:\n",
    "\n",
    "1. Load dataset (done! üéâ)\n",
    "2. Encode label features as numbers (not needed! done! ‚ö°Ô∏è)\n",
    "3. Normalize the data (not needed! done! üçæ)\n",
    "4. Separate the outcome variable and the input features (done! ‚òÄÔ∏è)\n",
    "5. Create a model using chosen features\n",
    "6. Run model on training data and measure error*\n",
    "7. Run model on test data, measure error*, plot predictions, interpret results\n",
    "\n",
    "We could use the same `regression_error()` function we used above to measure the error of our classifier model, but this could lead to $2$ issues. First, we don't have labels for the images in the test dataset, and second, the regression error reported might be higher than it actually is because an image with label $0$ that gets mislabeled as $5$ will count as being more wrong than if it was mislabeled $2$. And we don't want that. We just want to get the percentage of classifications that our model gets correctly.\n",
    "\n",
    "To simplify calculating the classification accuracy we can use the `CamUtils.classification_accuracy()` function. This function takes $2$ parameters, a list of files and a list of predictions. It will work with the test and train datasets and will calculate a more meaningful accuracy value than the one returned by `regression_error()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: create a brand new classifier\n",
    "# TODO: fit the model\n",
    "# TODO: run predictions\n",
    "# TODO: measure classification accuracy\n",
    "CamUtils.classification_accuracy(train_files, train_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That should look promising. Let's run this on our test dataset.\n",
    "\n",
    "Remember we already separated the test data features into a variable called `test_features` above.\n",
    "\n",
    "Now we just have to run the prediction and measure accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: run predictions on test data\n",
    "# TODO: measure classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Using just the first $10$ pixels of the image the classifier is able to label most of the images correctly.\n",
    "\n",
    "<span style=\"color:hotpink\">\n",
    "How can we improve this classifier? How does the number of features affect the classification accuracy of the test data<br>\n",
    "How does the choice of pixels affect the accuracy?<br><br>\n",
    "If you're curious, repeat the modeling above, but using the <code>SVC</code> classifier instead of <code>RandomForest</code>.<br>How does the choice of modeling technique affect the accuracy?<br><br>\n",
    "Experiment with some of these parameters and explain your findings below.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">EDIT THIS CELL WITH ANSWER</span>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPxe2qYxIG7EblrvD1C4Pmv",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.17 ('hf-model')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "89e384cab7c47fb35ec95d2248b519cf922ee174880eed636c26cdfb6c4df768"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
